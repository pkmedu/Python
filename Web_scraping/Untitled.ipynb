{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafa1af7-a039-4f27-9060-1d0198bcb35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44804120-325f-4809-821a-f698c3097803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapy in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (2.6.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from scrapy) (58.0.4)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from scrapy) (0.7.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from scrapy) (1.6.2)\n",
      "Requirement already satisfied: tldextract in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from scrapy) (3.3.1)\n",
      "Requirement already satisfied: Twisted>=17.9.0 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from scrapy) (22.4.0)\n",
      "Requirement already satisfied: service-identity>=16.0.0 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from scrapy) (21.1.0)\n",
      "Requirement already satisfied: zope.interface>=4.1.3 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from scrapy) (5.4.0)\n",
      "Requirement already satisfied: pyOpenSSL>=16.2.0 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from scrapy) (21.0.0)\n",
      "Requirement already satisfied: protego>=0.1.15 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from scrapy) (0.2.1)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from scrapy) (1.1.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from scrapy) (1.0.4)\n",
      "Requirement already satisfied: parsel>=1.5.0 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from scrapy) (1.6.0)\n",
      "Requirement already satisfied: lxml>=3.5.0 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from scrapy) (4.8.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from scrapy) (2.0.1)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from scrapy) (2.0.5)\n",
      "Requirement already satisfied: cryptography>=2.0 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from scrapy) (3.4.8)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from cryptography>=2.0->scrapy) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from cffi>=1.12->cryptography>=2.0->scrapy) (2.20)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
      "Requirement already satisfied: six>=1.6.0 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from parsel>=1.5.0->scrapy) (1.16.0)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from service-identity>=16.0.0->scrapy) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from service-identity>=16.0.0->scrapy) (0.2.8)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from service-identity>=16.0.0->scrapy) (21.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from Twisted>=17.9.0->scrapy) (3.10.0.2)\n",
      "Requirement already satisfied: twisted-iocpsupport<2,>=1.0.2 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from Twisted>=17.9.0->scrapy) (1.0.2)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from Twisted>=17.9.0->scrapy) (15.1.0)\n",
      "Requirement already satisfied: incremental>=21.3.0 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from Twisted>=17.9.0->scrapy) (21.3.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from Twisted>=17.9.0->scrapy) (21.0.0)\n",
      "Requirement already satisfied: Automat>=0.8.0 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from Twisted>=17.9.0->scrapy) (20.2.0)\n",
      "Requirement already satisfied: idna>=2.5 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from hyperlink>=17.1.1->Twisted>=17.9.0->scrapy) (3.2)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from tldextract->scrapy) (2.28.1)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from tldextract->scrapy) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from tldextract->scrapy) (3.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pmuhuri\\anaconda3\\new folder\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (1.26.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e125bb74-08bb-49dd-a45e-be67058a8d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.linkextractors import LinkExtractor\n",
    "from scrapy.spiders import CrawlSpider, Rule\n",
    "from scrapy.pipelines.files import FilesPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5198d602-a5cb-4ac7-8ed8-aa8bfa181798",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZipfilePipeline(FilesPipeline):\n",
    "    def file_path(self, request, response=None, info=None, *, item=None):\n",
    "        filename = request.url.split(\"/\")[-1]\n",
    "        return f\"zipfiles/{filename}\"\n",
    "\n",
    "\n",
    "class MepsSpider(CrawlSpider):\n",
    "    name = \"meps_spider\"\n",
    "    allowed_domains = [\"meps.ahrq.gov\"]\n",
    "    start_urls = [\"https://meps.ahrq.gov/data_files/pufs/\"]\n",
    "    custom_settings = {\n",
    "        \"USER_AGENT\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:103.0) Gecko/20100101 Firefox/103.0\",\n",
    "        \"ITEM_PIPELINES\": {\"apc.spiders.meps_spider.ZipfilePipeline\": 1},\n",
    "        \"FILES_STORE\": \"./\",\n",
    "    }\n",
    "\n",
    "    rules = (\n",
    "        Rule(\n",
    "            LinkExtractor(\n",
    "                allow=r\"https://meps.ahrq.gov/data_files/pufs/(.*)\",\n",
    "                restrict_css=r\"table td\",\n",
    "                deny_extensions=(\"zip\", \"exe\", \"shtml\"),\n",
    "            ),\n",
    "            callback=\"parse_page\",\n",
    "            follow=False,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    def parse_page(self, response):\n",
    "        zipfile_urls = []\n",
    "        link_extractor = LinkExtractor(\n",
    "            allow=r\"(.*).zip\",\n",
    "            deny_extensions=(),\n",
    "        )\n",
    "        for zipfile in link_extractor.extract_links(response):\n",
    "            zipfile_urls.append(zipfile.url)\n",
    "            # Comment out the following line to download the zipfiles\n",
    "            yield {\"url\": zipfile.url}\n",
    "        # Uncomment the following lines to download the zipfiles.\n",
    "        # return {\"file_urls\": zipfile_urls}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aec170b0-ca0c-4bed-b5da-13ddca157809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Python\\\\Web_Scraping'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902771f5-040c-4b8c-8641-e0ff66d7f1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
