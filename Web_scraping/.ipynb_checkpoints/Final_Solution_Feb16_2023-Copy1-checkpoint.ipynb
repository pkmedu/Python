{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd544913-00b9-44b4-a4ef-ea55f5a20db5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402 public use file names and description from the MEPS website\n",
      "\n",
      "Five file names and description below (out of 402)  from the .txt file created from the HTML data\n",
      "\n",
      "MEPS HC-226: MEPS Panel 23 Three-Year Longitudinal Data File\n",
      "\n",
      "MEPS HC-225: MEPS Panel 24 Longitudinal Data File\n",
      "\n",
      "MEPS HC-224: 2020 Full Year Consolidated Data File\n",
      "\n",
      "MEPS HC-223: 2020 Person Round Plan File\n",
      "\n",
      "MEPS HC-222: 2020 Medical Conditions File\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required Python libraries\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, re, Comment\n",
    "import pandas as pd  \n",
    "import xlsxwriter\n",
    "\n",
    "# Step 1: Scraping the primary \"MEPS data file website\", \n",
    "# finding the data file names that are within the \"option\"  \n",
    "# comment tags, and saving them in a csv file\n",
    "\n",
    "def extractOptions(inputData):\n",
    "    sub1 = str(re.escape('<option value=\"All\">All data files</option>'))\n",
    "    sub2 = str(re.escape('</select>'))\n",
    "    result = re.findall(sub1+\"(.*)\"+sub2, inputData, flags=re.S)\n",
    "    if len(result) > 0:\n",
    "        return result[0]\n",
    "\n",
    "def extractData(inputData):\n",
    "    sub1 = str(re.escape('>'))\n",
    "    sub2 = str(re.escape('</option>'))\n",
    "    result =  re.findall(sub1+\"(.*)\"+sub2, inputData, flags=re.S)\n",
    "    if len(result) > 0:\n",
    "        return result[0]\n",
    "    return ''\n",
    "\n",
    "def main(base_url):\n",
    "    response = requests.get(base_url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "    for c in comments:\n",
    "        if '<select id=\"pufnumber\" size=1 name=\"cboPufNumber\">' in c:\n",
    "            #print(c.option.text)\n",
    "            options = extractOptions(c)\n",
    "            ops = options.splitlines() #split text into lines\n",
    "            \n",
    "            fp = open(r'C:\\Data\\MEPS_fn.txt', 'w')\n",
    "            filtered = []\n",
    "            unwanteds = ['-IC', 'replaced', 'CD-ROM']\n",
    "            for op in ops:\n",
    "                data = extractData(op)\n",
    "                if data.startswith(('MEPS HC', 'HC')) and \\\n",
    "                not any(item in data for item in unwanteds):\n",
    "                    fp.write(data +'\\n') \n",
    "                    filtered.append(data)\n",
    "            fp.close()   \n",
    "            print(len(filtered), 'public use file names and description from the MEPS website')    \n",
    "            print ()\n",
    "            # open, read , and print 5 lines from the file\n",
    "            print ('Five file names and description below (out of 402)  from the .txt file created from the HTML data')\n",
    "            print ()\n",
    "            file = open(r'C:\\Data\\MEPS_fn.txt')\n",
    "            content = file.readlines()\n",
    "            for item in content[:5]:   print(item)\n",
    "\n",
    "main('https://meps.ahrq.gov/data_stats/download_data_files.jsp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0036b29d-573a-4dd1-ae17-fe82015069b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 402 MEPS public-use filenames listed in the MEPS Data File Web Page.\n",
      "\n",
      "Five sample data file URLs (out of 402) constrcuted from the HTML data\n",
      "['https://meps.ahrq.gov/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-226']\n",
      "['https://meps.ahrq.gov/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-225']\n",
      "['https://meps.ahrq.gov/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-224']\n",
      "['https://meps.ahrq.gov/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-223']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Creating a Python Pandas DataFrame based on the .txt file created in the previous step\n",
    "colname=['fn']\n",
    "df1 = pd.read_csv(r'C:/Data/MEPS_fn.txt',  sep='\\t', names = colname)\n",
    "\n",
    "# Construct the data file URL (domain + query format)\n",
    "df1['url1'] = \"https://meps.ahrq.gov/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-\" \\\n",
    "+ df1['fn'].str.extract(r\"(\\d+[A-Z]*)\").sum(axis=1).astype(str)\n",
    "\n",
    "#  Drop the the column named fn\n",
    "df1 = df1.drop(columns=['fn'])\n",
    "\n",
    "print('There are', len(df1), 'MEPS public-use filenames listed in the MEPS Data File Web Page.')\n",
    "print()\n",
    "list = df1.values.tolist()\n",
    "\n",
    "print('Five sample data file URLs (out of 402) constrcuted from the HTML data')\n",
    "for item in list[:4]:   print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b585e1c9-bb50-4192-a485-e4c350d44f9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 1,154  MEPS-HC data file format-specific URLs listed on the MEPS website\n",
      "\n",
      "Below is a small portion of the bulk output saved in a file.\n",
      "(Sample MEPS data file-URL along its five data format-specific URLs - out of 1,154 URLs)\n",
      "\n",
      "URL for MEPS HC-226: MEPS Panel 23 Three-Year Longitudinal Data File\n",
      "\n",
      "https://meps.ahrq.gov/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-226\n",
      "\n",
      "URLs for the data file in multiple formats, if available\n",
      "\n",
      "https://meps.ahrq.gov/data_files/pufs/h226/h226dat.zip\n",
      "\n",
      "https://meps.ahrq.gov/data_files/pufs/h226/h226ssp.zip\n",
      "\n",
      "https://meps.ahrq.gov/data_files/pufs/h226/h226v9.zip\n",
      "\n",
      "https://meps.ahrq.gov/data_files/pufs/h226/h226dta.zip\n",
      "\n",
      "https://meps.ahrq.gov/data_files/pufs/h226/h226xlsx.zip\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Scraping the MEPS websites and displaying the manipulated data \n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "with open(r'C:\\Data\\urls.markdown', 'w') as f:\n",
    "    url2_str_list = []\n",
    "    for item in df1.index:\n",
    "        url1_str = df1['url1'][item]\n",
    "        response = requests.get(url1_str)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        li = soup.find(class_ = \"OrangeBox\").text\n",
    "        print('URL for', li, file = f)  \n",
    "        print(url1_str, file = f)\n",
    "        print('URLs for the data file in multiple formats, if available',file = f)\n",
    "        for link in soup.find_all('a'):\n",
    "            if link.text.endswith('ZIP'):\n",
    "                url2_str = 'https://meps.ahrq.gov' + link.get('href').strip('..')\n",
    "                print(url2_str, file = f)       \n",
    "                url2_str_list.append(url2_str)\n",
    "                                \n",
    "print('A total of', f\"{len(url2_str_list):,d}\", ' MEPS-HC data file format-specific URLs listed on the MEPS website') \n",
    "print()\n",
    "print ('Below is a small portion of the bulk output saved in a file.')\n",
    "print(\"(Sample MEPS data file-URL along its five data format-specific URLs - out of 1,154 URLs)\")\n",
    "print()   \n",
    "file = open(r'C:\\Data\\urls.markdown')\n",
    "content = file.readlines()\n",
    "for item in content[:8]:     print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c368c83b-dbe1-4fb9-b101-ede55dca8ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Step 3: Scraping the MEPS websites and displaying the manipulated data \n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "url2_str_list = []\n",
    "for item in df1.index:\n",
    "    url1_str = df1['url1'][item]\n",
    "    response = requests.get(url1_str)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    li = soup.find(class_ = \"OrangeBox\").text\n",
    "    print('URL for', li)  \n",
    "    print(url1_str)\n",
    "    print('URLs for the data file in multiple formats, if available')\n",
    "    for link in soup.find_all('a'):\n",
    "        if link.text.endswith('ZIP'):\n",
    "            url2_str = 'https://meps.ahrq.gov' + link.get('href').strip('..')\n",
    "            print(url2_str)       \n",
    "            url2_str_list.append(url2_str)\n",
    "print('A total of', f\"{len(url2_str_list):,d}\", ' MEPS-HC data file format-specific URLs listed on the MEPS website') \n",
    "  with open('out.txt', 'w') as f:\n",
    "        print('Filename:', filename, file=f) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302ddc78-66d1-45b3-9b84-6a3443a8c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to markdown Final_Solution_Feb16_2023.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
