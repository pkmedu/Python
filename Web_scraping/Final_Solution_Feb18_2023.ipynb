{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd544913-00b9-44b4-a4ef-ea55f5a20db5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365 public use file names and description from the MEPS website\n",
      "===========\n",
      "Five file names/description below from the .txt file created from the HTML data\n",
      "===========\n",
      "MEPS HC-226: MEPS Panel 23 Three-Year Longitudinal Data File\n",
      "\n",
      "MEPS HC-225: MEPS Panel 24 Longitudinal Data File\n",
      "\n",
      "MEPS HC-224: 2020 Full Year Consolidated Data File\n",
      "\n",
      "MEPS HC-223: 2020 Person Round Plan File\n",
      "\n",
      "MEPS HC-222: 2020 Medical Conditions File\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required Python libraries\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, re, Comment\n",
    "import pandas as pd  \n",
    "\n",
    "\n",
    "# Step 1: Create a .txt file by scraping the the MEPS website's option tags' commented data\n",
    "\n",
    "def extractOptions(inputData):\n",
    "    sub1 = str(re.escape('<option value=\"All\">All data files</option>'))\n",
    "    sub2 = str(re.escape('</select>'))\n",
    "    result = re.findall(sub1+\"(.*)\"+sub2, inputData, flags=re.S)\n",
    "    if len(result) > 0:\n",
    "        return result[0]\n",
    "\n",
    "def extractData(inputData):\n",
    "    sub1 = str(re.escape('>'))\n",
    "    sub2 = str(re.escape('</option>'))\n",
    "    result =  re.findall(sub1+\"(.*)\"+sub2, inputData, flags=re.S)\n",
    "    if len(result) > 0:\n",
    "        return result[0]\n",
    "    return ''\n",
    "\n",
    "def main(base_url):\n",
    "    response = requests.get(base_url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "    for c in comments:\n",
    "        if '<select id=\"pufnumber\" size=1 name=\"cboPufNumber\">' in c:\n",
    "            #print(c.option.text)\n",
    "            options = extractOptions(c)\n",
    "            ops = options.splitlines() #split text into lines\n",
    "            \n",
    "            fp = open(r'C:\\Data\\MEPS_fn.txt', 'w')\n",
    "            filtered = []\n",
    "            unwanteds = ['-IC', 'CD-ROM', 'replaced', 'Population Characteristics']\n",
    "            for op in ops:\n",
    "                data = extractData(op)\n",
    "                if data.startswith(('MEPS HC', 'HC')) and not any(item in data for item in unwanteds):\n",
    "                    fp.write(data +'\\n') \n",
    "                    filtered.append(data)\n",
    "            fp.close()   \n",
    "            print(len(filtered), 'public use file names and description from the MEPS website')    \n",
    "            print(\"===========\")\n",
    "            # open, read , and print 5 lines from the file\n",
    "            print ('Five file names/description below from the .txt file created from the HTML data')\n",
    "            print(\"===========\")\n",
    "            file = open(r'C:\\Data\\MEPS_fn.txt')\n",
    "            content = file.readlines()\n",
    "            for item in content[:5]:   print(item)\n",
    "\n",
    "main('https://meps.ahrq.gov/data_stats/download_data_files.jsp')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0036b29d-573a-4dd1-ae17-fe82015069b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 365 MEPS public-use filenames listed in the MEPS Data File Web Page.\n",
      "===========\n",
      "Five data file URLs (out of over one thousand) constrcuted from the HTML data\n",
      "['https://meps.ahrq.gov/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-226']\n",
      "['https://meps.ahrq.gov/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-225']\n",
      "['https://meps.ahrq.gov/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-224']\n",
      "['https://meps.ahrq.gov/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-223']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Constrct the the data file URL from the .txt file created in the previous step\n",
    "colname=['fn']\n",
    "df1 = pd.read_csv(r'C:/Data/MEPS_fn.txt',  sep='\\t', names = colname)\n",
    "\n",
    "# Construct the data file URL (domain + query format)\n",
    "df1['url1'] = \"https://meps.ahrq.gov/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-\" \\\n",
    "+ df1['fn'].str.extract(r\"(\\d+[A-Z]*)\").sum(axis=1).astype(str)\n",
    "\n",
    "#  Drop the the column named fn\n",
    "df1 = df1.drop(columns=['fn'])\n",
    "\n",
    "print('There are', len(df1), 'MEPS public-use filenames listed in the MEPS Data File Web Page.')\n",
    "print(\"===========\")\n",
    "list = df1.values.tolist()\n",
    "\n",
    "print('Five data file URLs (out of over one thousand) constrcuted from the HTML data')\n",
    "for item in list[:4]:   print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b585e1c9-bb50-4192-a485-e4c350d44f9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 1,066  MEPS-HC data file format-specific URLs listed on the MEPS website\n",
      "===========\n",
      "Example output: Sample results for one MEPS data file out of hundreds - read from a Python-generated output file\n",
      "\n",
      "URL below for MEPS HC-226: MEPS Panel 23 Three-Year Longitudinal Data File\n",
      "\n",
      "https://meps.ahrq.gov/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-226\n",
      "\n",
      "URL(s) below for the above data file in one or  more formats (.dat, .ssp, sasv9, dta, .xlsx)\n",
      "\n",
      "https://meps.ahrq.gov/data_files/pufs/h226/h226dat.zip\n",
      "\n",
      "https://meps.ahrq.gov/data_files/pufs/h226/h226ssp.zip\n",
      "\n",
      "https://meps.ahrq.gov/data_files/pufs/h226/h226v9.zip\n",
      "\n",
      "https://meps.ahrq.gov/data_files/pufs/h226/h226dta.zip\n",
      "\n",
      "https://meps.ahrq.gov/data_files/pufs/h226/h226xlsx.zip\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Create data file format-specific URLs from the websites' HTML data for each of the data  files\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "with open(r'C:\\Data\\urls.markdown', 'w') as f:\n",
    "    url2_str_list = []\n",
    "    for item in df1.index:\n",
    "        url1_str = df1['url1'][item]\n",
    "        response = requests.get(url1_str)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        li = soup.find (class_ = \"OrangeBox\").text\n",
    "        print('URL below for', li, file = f)  \n",
    "        print(url1_str, file = f)\n",
    "        print('URL(s) below for the above data file in one or  more formats (.dat, .ssp, sasv9, dta, .xlsx)',file = f)\n",
    "        for link in soup.find_all('a'):\n",
    "            if link.text.endswith('ZIP'):\n",
    "                url2_str = 'https://meps.ahrq.gov' + link.get('href').strip('..')\n",
    "                print(url2_str, file = f)       \n",
    "                url2_str_list.append(url2_str)\n",
    "                                \n",
    "print('A total of', f\"{len(url2_str_list):,d}\", ' MEPS-HC data file format-specific URLs listed on the MEPS website') \n",
    "print(\"===========\")\n",
    "print ('Example output: Sample results for one MEPS data file out of hundreds - read from a Python-generated output file')\n",
    "print()\n",
    "file = open(r'C:\\Data\\urls.markdown')\n",
    "content = file.readlines()\n",
    "for item in content[:8]:     print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302ddc78-66d1-45b3-9b84-6a3443a8c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to markdown Final_Solution_Feb18_2023.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf2f8221-80d8-4488-809e-ed4bfa6a5c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Final_Solution_Feb18_2023.ipynb to python\n",
      "[NbConvertApp] Writing 4402 bytes to Final_Solution_Feb18_2023.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to python Final_Solution_Feb18_2023.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bf21ce-f488-42b7-9d21-a6c0fb5f35da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
